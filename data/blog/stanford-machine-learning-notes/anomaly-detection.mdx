---
title: Anomaly Detection
published: true
createdAt: 2019-03-20T14:26:44.585Z
updatedAt: 2019-06-05T01:50:55.398Z
categories:
  - Programming
  - Algorithms
  - Machine Learning
  - Neural Networks
  - Stanford
---

import { M } from '../../../src/components/math';

Anomaly detection is useful for predicting anomalous datapoints out of a large group. In order to do this, you need to
have training data that has labeled anomalies. Anomaly detection works best when there is...

- a large number of negative examples
- a small number of positive examples
- the positive examples are not well known (there can be many anomaly types)

The algorithm works by first choosing features of <M i="x^{(i)}"/> that you think might be likely to be anomalous. Then
find the average and standard deviation of each of the features

<M b="
  \begin{aligned}
    \mu_j &= \frac{1}{m} \sum_{i=1}^m x^{(i)}_j \\
    \sigma^2_j &= \frac{1}{m} \sum_{i=1}^m (x_j^{(i)} - \mu_j)^2
  \end{aligned}
"/>

Given a new example x, compute the guassian probability of x -> p(x). `X` is considered an anomaly if the <M i="p(x)" />
value is smaller than an <M i="\epsilon" /> value which can be a learnable parameter since the dataset has labeled
anomalous examples.

<M b="
  p(x)
  = \prod_{j=1}^n p(x_j;\mu_j,\sigma^2_j)
  = \prod_{j=1}^n \frac{1}{\sqrt{2 \pi \sigma_j}} exp(- \frac{(x_j - \mu_j)^2}{2 \sigma^2_j})
"/>

The last step gives the Gaussian probability, meaning that if a feature is more standard deviations away from the mean,
then it has a smaller Gaussian probability. Therefore, the last product part multiplied the Gaussian probabilities for
each feature of the example together. If all of the features lie somewhere close to the mean then the resulting number
will be relatively larger, and if the numbers are many standard deviations away from the mean then `p(x)` will be very
small. The example is considered an anomaly if it is smaller than some predetermined <M i="\epsilon"/>
threshold.
